{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input the number of articles:1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 1. Load\n",
    "with open(\"./dataset/podcast.txt\", 'r') as f:\n",
    "    f_podcast = f.read()\n",
    "\n",
    "f_articles = ''\n",
    "data_len = int(input(\"input the number of articles:\"))\n",
    "for i in range(1, data_len):\n",
    "    path = './dataset/articles/%d.txt' %i\n",
    "    f = open(path, 'r')\n",
    "    f_articles += f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. tokenize lower\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "podtokens = nltk.wordpunct_tokenize(f_podcast)\n",
    "podwords = [w.lower() for w in podtokens]\n",
    "\n",
    "arttokens = nltk.wordpunct_tokenize(f_articles)\n",
    "artwords = [w.lower() for w in arttokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile('.*[^a-z].*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphaFreqDist(words):\n",
    "    alphalist = list()\n",
    "    for word in words:\n",
    "        if not pattern.match(word): \n",
    "            alphalist.append(word)\n",
    "    alphafd = FreqDist(alphalist)\n",
    "    return alphafd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphaStopFreqDist(words, stoplist):\n",
    "    alphalist = list()\n",
    "    for word in words:\n",
    "        if not pattern.match(word): \n",
    "            if not word in stoplist:\n",
    "                alphalist.append(word)\n",
    "    alphafd = FreqDist(alphalist)\n",
    "    return alphafd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramDist(words, stoplist):\n",
    "    bilist = list()\n",
    "    uniDist = alphaStopFreqDist(words, stoplist)\n",
    "    for i in range(1, len(words)):\n",
    "        if words[i-1] in uniDist and words[i] in uniDist: \n",
    "            biword = words[i-1] + ' ' + words[i] \n",
    "            bilist.append(biword)\n",
    "    biDist = FreqDist(bilist)\n",
    "    return biDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 54493\n",
      "that 50035\n",
      "to 46133\n",
      "of 41445\n",
      "and 36333\n",
      "a 34858\n",
      "i 32262\n",
      "you 29171\n",
      "it 27498\n",
      "s 25019\n",
      "in 23789\n",
      "is 20611\n",
      "we 17338\n",
      "think 14105\n",
      "so 13315\n",
      "be 12955\n",
      "are 12562\n",
      "have 12175\n",
      "they 11898\n",
      "people 11448\n"
     ]
    }
   ],
   "source": [
    "p_afdist = alphaFreqDist(podwords)\n",
    "sorted_afdist = {k:v for k,v in sorted(p_afdist.items(), key=lambda item:item[1], reverse=True)}\n",
    "for key in list(sorted_afdist.keys())[:20]:\n",
    "    print(key, sorted_afdist[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 57276\n",
      "a 34186\n",
      "of 33124\n",
      "to 30358\n",
      "and 28296\n",
      "in 20474\n",
      "that 14760\n",
      "or 14673\n",
      "is 14392\n",
      "can 12734\n",
      "for 11601\n",
      "with 10948\n",
      "may 10818\n",
      "as 9217\n",
      "people 8480\n",
      "it 8206\n",
      "are 7578\n",
      "this 7369\n",
      "they 6898\n",
      "person 6200\n"
     ]
    }
   ],
   "source": [
    "a_afdist = alphaFreqDist(artwords)\n",
    "sorted_afdist = {k:v for k,v in sorted(a_afdist.items(), key=lambda item:item[1], reverse=True)}\n",
    "for key in list(sorted_afdist.keys())[:20]:\n",
    "    print(key, sorted_afdist[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['the', 'that', 'd', 'you', 'they', 's', 'to', \\\n",
    "             'be', 'of', 'the', 'in', 'we', 'so', \\\n",
    "             'it', 'was', 'are', 'i', 'am', 'she', \\\n",
    "             'had', 'been', 'is', 'have', 'could', \\\n",
    "             'not', 'her', 'he', 'do', 'and', 'would', \\\n",
    "             'such', 'a', 'his', 'must', 'as', 't', 'or', 're', \\\n",
    "            'this', 'at', 'on', 'with', 'one', 'then', 'if']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may 10818\n",
      "people 8480\n",
      "person 6200\n",
      "symptoms 5315\n",
      "also 5118\n",
      "doctor 4528\n",
      "cause 3592\n",
      "treatment 3547\n",
      "help 3338\n",
      "blood 3297\n",
      "cancer 3123\n",
      "include 3054\n",
      "pain 2924\n",
      "body 2686\n",
      "however 2631\n",
      "use 2528\n",
      "risk 2504\n",
      "disease 2270\n",
      "effects 2234\n",
      "drug 2215\n",
      "skin 2207\n",
      "health 2170\n",
      "study 2060\n",
      "one 2013\n",
      "medical 1987\n"
     ]
    }
   ],
   "source": [
    "asfdist = alphaStopFreqDist(artwords, stopwords)\n",
    "sorted_asfdist = {k:v for k,v in sorted(asfdist.items(), key=lambda item:item[1], reverse=True)}\n",
    "for key in list(sorted_asfdist.keys())[:25]:\n",
    "    print(key, sorted_asfdist[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "think 14105\n",
      "people 11448\n",
      "like 10484\n",
      "robert 8048\n",
      "wiblin 8036\n",
      "would 6277\n",
      "really 6121\n",
      "one 5766\n",
      "things 4933\n",
      "yeah 4929\n",
      "kind 4507\n",
      "lot 4436\n",
      "going 4249\n",
      "could 4245\n",
      "get 4128\n",
      "say 3618\n",
      "know 3522\n",
      "well 3509\n",
      "actually 3475\n",
      "something 3355\n",
      "good 3353\n",
      "much 3329\n",
      "work 3307\n",
      "might 3200\n",
      "also 2991\n"
     ]
    }
   ],
   "source": [
    "asfdist = alphaStopFreqDist(podwords, stopwords)\n",
    "sorted_asfdist = {k:v for k,v in sorted(asfdist.items(), key=lambda item:item[1], reverse=True)}\n",
    "for key in list(sorted_asfdist.keys())[:25]:\n",
    "    print(key, sorted_asfdist[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robert wiblin 7970\n",
      "little bit 716\n",
      "seems like 671\n",
      "something like 572\n",
      "things like 442\n",
      "machine learning 442\n",
      "would say 422\n",
      "effective altruism 414\n",
      "one thing 386\n",
      "brian christian 379\n",
      "david chalmers 348\n",
      "dave denkenberger 340\n",
      "hilary greaves 334\n",
      "many people 322\n",
      "paul christiano 321\n",
      "tom kalil 321\n",
      "katja grace 320\n",
      "philip tetlock 298\n",
      "really important 291\n",
      "glen weyl 291\n"
     ]
    }
   ],
   "source": [
    "bidist = bigramDist(podwords, stopwords)\n",
    "sorted_bidict = {k: v for k, v in sorted(bidist.items(), key=lambda item: item[1], reverse=True)}\n",
    "for key in list(sorted_bidict.keys())[:20]:\n",
    "    print(key, sorted_bidict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side effects 1343\n",
      "may also 1041\n",
      "blood pressure 776\n",
      "doctor may 711\n",
      "may help 611\n",
      "person may 523\n",
      "people may 476\n",
      "immune system 463\n",
      "may cause 383\n",
      "united states 380\n",
      "may experience 355\n",
      "many people 355\n",
      "trokendi xr 333\n",
      "bipolar disorder 322\n",
      "may include 310\n",
      "allergic reaction 302\n",
      "birth control 292\n",
      "mental health 292\n",
      "weight loss 289\n",
      "treatment options 285\n"
     ]
    }
   ],
   "source": [
    "bidist = bigramDist(artwords, stopwords)\n",
    "sorted_bidict = {k: v for k, v in sorted(bidist.items(), key=lambda item: item[1], reverse=True)}\n",
    "for key in list(sorted_bidict.keys())[:20]:\n",
    "    print(key, sorted_bidict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutualinfo(words, stoplist, threshold):\n",
    "    assoclist = list()\n",
    "    uniDist = alphaStopFreqDist(words, stoplist)\n",
    "    for i in range(1, len(words)):\n",
    "        if (uniDist[words[i-1]] > threshold) and (uniDist[words[i]] > threshold): \n",
    "            biword = words[i-1] + ' ' + words[i]\n",
    "            assoclist.append(biword)\n",
    "    assocDist = FreqDist(assoclist)\n",
    "    arDist = FreqDist()\n",
    "    N = len(words)\n",
    "    for wordstring in assocDist.keys():\n",
    "        wordlist = str.split(wordstring, ' ')\n",
    "        w0 = wordlist[0]\n",
    "        w1 = wordlist[1]\n",
    "        ar = (assocDist[wordstring] * N * N) / (1.0 *uniDist[w0] * uniDist[w1]) \n",
    "        ar_log2 = log(ar, 2)\n",
    "        arDist[wordstring] = ar_log2 \n",
    "    return arDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carrick flynn 40.01549128189736\n",
      "esther duflo 40.01549128189736\n",
      "cato unbound 40.01549128189736\n",
      "clay shirky 40.01549128189736\n",
      "geoffrey irving 39.60045378261852\n",
      "leo szilard 39.60045378261852\n",
      "karthik muralidharan 39.60045378261852\n",
      "yasser arafat 39.60045378261852\n",
      "lant pritchett 39.60045378261852\n",
      "deng xiaoping 39.60045378261852\n",
      "enhanced fermentation 39.60045378261852\n",
      "louisiana gubernatorial 39.60045378261852\n",
      "guamanian cuisine 39.60045378261852\n",
      "el salvador 39.60045378261852\n",
      "burkina faso 39.60045378261852\n",
      "warren buffet 39.43052878117621\n",
      "gitcoin clr 39.43052878117621\n",
      "destruct timers 39.43052878117621\n",
      "puerto rico 39.278525687731154\n",
      "von neumann 39.278525687731154\n"
     ]
    }
   ],
   "source": [
    "p_MIdist = mutualinfo( podwords, stopwords , 2)\n",
    "# only showing the top 20 scoring bigrams in the dictionary.\n",
    "sorted_MIdist = {k: v for k, v in sorted(p_MIdist.items(), key=lambda item: item[1], reverse=True)}\n",
    "for pair in list(sorted_MIdist.keys())[:20]:\n",
    "    print(pair, sorted_MIdist[pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lichen planus 39.22619512963619\n",
      "vas deferens 39.22619512963619\n",
      "percutaneous nephrolithotomy 39.22619512963619\n",
      "bok choy 39.22619512963619\n",
      "owen kramer 39.22619512963619\n",
      "carnegie mellon 39.22619512963619\n",
      "locum tenens 39.22619512963619\n",
      "faraway lands 39.22619512963619\n",
      "chlorophytum borivilianum 39.22619512963619\n",
      "epidermal necrolysis 38.81115763035734\n",
      "hong kong 38.81115763035734\n",
      "albert einstein 38.81115763035734\n",
      "vice versa 38.81115763035734\n",
      "acsm ep 38.81115763035734\n",
      "dos reis 38.81115763035734\n",
      "seebri neohaler 38.81115763035734\n",
      "alana biggers 38.81115763035734\n",
      "lou gehrig 38.81115763035734\n",
      "retinitis pigmentosa 38.81115763035734\n",
      "telogen effluvium 38.81115763035734\n"
     ]
    }
   ],
   "source": [
    "a_MIdist = mutualinfo( artwords, stopwords , 2)\n",
    "# only showing the top 20 scoring bigrams in the dictionary.\n",
    "sorted_MIdist = {k: v for k, v in sorted(a_MIdist.items(), key=lambda item: item[1], reverse=True)}\n",
    "for pair in list(sorted_MIdist.keys())[:20]:\n",
    "    print(pair, sorted_MIdist[pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
